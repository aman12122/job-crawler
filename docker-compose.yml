services:
  db:
    image: postgres:15-alpine
    container_name: job-crawler-db
    environment:
      POSTGRES_USER: jobcrawler
      POSTGRES_PASSWORD: jobcrawler_dev
      POSTGRES_DB: job_crawler
    ports:
      - "5434:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scraper/sql:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U jobcrawler -d job_crawler"]
      interval: 5s
      timeout: 5s
      retries: 5

  web:
    build:
      context: ./web
      dockerfile: Dockerfile
    container_name: job-crawler-web
    ports:
      - "3000:3000"
    environment:
      DATABASE_HOST: db
      DATABASE_PORT: 5432
      DATABASE_NAME: job_crawler
      DATABASE_USER: jobcrawler
      DATABASE_PASSWORD: jobcrawler_dev
    depends_on:
      db:
        condition: service_healthy

  scraper:
    build:
      context: ./scraper
      dockerfile: Dockerfile
    container_name: job-crawler-scraper
    # Overwrite command to keep container running if needed, or just let it exit
    # For now, we'll just let it run the main crawler and exit
    environment:
      DATABASE_HOST: db
      DATABASE_PORT: 5432
      DATABASE_NAME: job_crawler
      DATABASE_USER: jobcrawler
      DATABASE_PASSWORD: jobcrawler_dev
    depends_on:
      db:
        condition: service_healthy
    # Don't restart automatically as it's a one-off job
    restart: "no"

volumes:
  postgres_data:
